{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, List\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UdemyAPI:\n",
    "    def __init__(self) -> None:\n",
    "        # find .env automagically by walking up directories until it's found\n",
    "        dotenv_path = find_dotenv()\n",
    "\n",
    "        # load up the entries as environment variables\n",
    "        load_dotenv(dotenv_path)\n",
    "\n",
    "        self.CLIENT_ID = os.environ.get(\"UDEMY_CLIENT_ID\")\n",
    "        self.CLIENT_SECRET = os.environ.get(\"UDEMY_CLIENT_SECRET\")\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    \n",
    "    def request_data(self, url):\n",
    "        try:\n",
    "            response = self.session.get(url, auth=HTTPBasicAuth(self.CLIENT_ID, self.CLIENT_SECRET))\n",
    "\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "            print(errh)\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "            print(errc)\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "            print(errt)\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(err)\n",
    "    \n",
    "    def request_course_data(self):\n",
    "        pass\n",
    "    \n",
    "    def request_course_details(self):\n",
    "        pass\n",
    "    \n",
    "    def request_course_curriculum(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the course details data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/courses_details_2023-06-28.json', 'r') as f:\n",
    "    course_details = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "url = []\n",
    "id = []\n",
    "headline = []\n",
    "description = []\n",
    "primary_category = []\n",
    "primary_subcategory = []\n",
    "\n",
    "for course in course_details:\n",
    "    title.append(course['title'])\n",
    "    url.append(course['url'])\n",
    "    id.append(course['id'])\n",
    "    headline.append(course['headline'])\n",
    "    description.append(course['description'])\n",
    "    primary_category.append(course['primary_category']['title_cleaned'])\n",
    "    primary_subcategory.append(course['primary_subcategory']['title_cleaned'])\n",
    "    \n",
    "\n",
    "    \n",
    "d = {'title': title, 'url': url, 'id': id, 'headline': headline, 'description': description, 'primary_category': primary_category, 'primary_subcategory': primary_subcategory}\n",
    "df_courses = pd.DataFrame.from_dict(d, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses.to_csv('../data/interim/courses_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_text = soup.get_text()\n",
    "    clean_text = clean_text.replace('\\xa0', ' ')\n",
    "    return clean_text\n",
    "df_courses['description_cleaned'] = df_courses['description'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    # Initialize the TF-IDF vectorizer with n-gram range from 1 to 3 (unigrams, bigrams, and trigrams)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
    "\n",
    "    # Fit and transform the text\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "    # Get the feature names (words, bigrams, and trigrams)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Create a dictionary to store the word scores\n",
    "    word_scores = {}\n",
    "\n",
    "    # Loop over the features and their scores\n",
    "    for col in tfidf_matrix.nonzero()[1]:\n",
    "        word_scores[feature_names[col]] = tfidf_matrix[0, col]\n",
    "\n",
    "    # Sort the words based on their scores in descending order\n",
    "    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract the top 10 most important words, bigrams, and trigrams\n",
    "    top_keywords = [keyword for keyword, score in sorted_words[:5]]\n",
    "\n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_courses.loc[3, 'title'] + \" \" + df_courses.loc[3, 'headline']\n",
    "keywords = extract_keywords(text)\n",
    "print(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online_courses_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
